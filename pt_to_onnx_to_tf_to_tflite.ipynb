{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f16bc25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Downloading onnx-1.12.0-cp39-cp39-win_amd64.whl (11.5 MB)\n",
      "     ---------------------------------------- 11.5/11.5 MB 5.3 MB/s eta 0:00:00\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.13.1-cp39-cp39-win_amd64.whl (5.9 MB)\n",
      "     ---------------------------------------- 5.9/5.9 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting onnxsim\n",
      "  Downloading onnxsim-0.4.10-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx) (1.22.4+vanilla)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx) (4.3.0)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnxruntime) (22.11.23)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "     ---------------------------------------- 6.5/6.5 MB 5.2 MB/s eta 0:00:00\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnxruntime) (21.3)\n",
      "Collecting rich\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "     -------------------------------------- 237.5/237.5 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->onnxruntime) (3.0.9)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich->onnxsim) (2.13.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "     ---------------------------------------- 51.1/51.1 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "     -------------------------------------- 532.6/532.6 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyreadline3, mpmath, commonmark, sympy, rich, onnx, humanfriendly, onnxsim, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 commonmark-0.9.1 humanfriendly-10.0 mpmath-1.2.1 onnx-1.12.0 onnxruntime-1.13.1 onnxsim-0.4.10 pyreadline3-3.4.1 rich-12.6.0 sympy-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime onnxsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b189f3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx-tf\n",
      "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
      "     -------------------------------------- 226.1/226.1 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: onnx>=1.10.2 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx-tf) (1.12.0)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.19.0-cp39-cp39-win_amd64.whl (742 kB)\n",
      "     -------------------------------------- 742.5/742.5 kB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx-tf) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx>=1.10.2->onnx-tf) (4.3.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx>=1.10.2->onnx-tf) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from onnx>=1.10.2->onnx-tf) (1.22.4+vanilla)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-addons->onnx-tf) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nda\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->tensorflow-addons->onnx-tf) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow-addons, onnx-tf\n",
      "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.19.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0421eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c24384",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'data/images/train'\n",
    "images = os.listdir(img_dir)\n",
    "random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a746cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a098175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NDA\\PycharmProjects\\detect people\\yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5ff6ec3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import onnx_graphsurgeon failure: No module named 'onnx_graphsurgeon'\n",
      "Namespace(weights='tiny_100_640.pt', img_size=[640, 640], batch_size=1, dynamic=False, dynamic_batch=False, grid=True, end2end=True, max_wh=640, topk_all=100, iou_thres=0.65, conf_thres=0.35, device='cpu', simplify=True, include_nms=False, fp16=False, int8=False)\n",
      "Fusing layers... \n",
      "IDetect.fuse\n",
      "\n",
      "Starting TorchScript export with torch 1.12.1+cpu...\n",
      "TorchScript export success, saved as tiny_100_640.torchscript.pt\n",
      "CoreML export failure: No module named 'coremltools'\n",
      "\n",
      "Starting TorchScript-Lite export with torch 1.12.1+cpu...\n",
      "TorchScript-Lite export success, saved as tiny_100_640.torchscript.ptl\n",
      "\n",
      "Starting ONNX export with onnx 1.12.0...\n",
      "onnxruntime\n",
      "\n",
      "Starting to simplify ONNX...\n",
      "ONNX export success, saved as tiny_100_640.onnx\n",
      "\n",
      "Export complete (11.18s). Visualize with https://github.com/lutzroeder/netron.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR  2022-12-11 torch 1.12.1+cpu CPU\n",
      "\n",
      "C:\\Users\\NDA\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 208 layers, 6007596 parameters, 0 gradients, 13.0 GFLOPS\n",
      "C:\\Users\\NDA\\PycharmProjects\\detect people\\yolov7\\models\\yolo.py:150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
      "C:\\Users\\NDA\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:4189: UserWarning: Exporting aten::index operator of advanced indexing in opset 12 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights tiny_100_640.pt --grid --end2end --simplify \\\n",
    "--topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640 --max-wh 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33a857d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 18:42:07,059 - onnx-tf - INFO - Start converting onnx pb to tf saved model\n",
      "2022-12-11 18:42:07.173761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From C:\\Users\\NDA\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "2022-12-11 18:42:19,189 - onnx-tf - INFO - Converting completes successfully.\n",
      "INFO:onnx-tf:Converting completes successfully.\n"
     ]
    }
   ],
   "source": [
    "!onnx-tf convert -i tiny_100_640.onnx -o /yolo7/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a18950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b859ea",
   "metadata": {},
   "source": [
    "Convert to tflite float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('/yolo7/')\n",
    "tflite_model = converter.convert()\n",
    "with open('yolov7_model_16.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f5f26",
   "metadata": {},
   "source": [
    "Convert to tflite float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70cf4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('/yolo7/')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "with open('yolov7_model_99.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e569c18a",
   "metadata": {},
   "source": [
    "Convert to tflite int8 with quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44d545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530166bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_data_gen():\n",
    "    a = []\n",
    "    for i in range(150):\n",
    "        file_name = images[i]\n",
    "        img = cv2.imread(img_dir + file_name)\n",
    "        img = cv2.resize(img, (640, 640))\n",
    "        img = img / 255.0\n",
    "        img = img.astype(np.float32)\n",
    "        a.append(img)\n",
    "    a = np.array(a)\n",
    "    print(a.shape) # a is np array of 150 3D images\n",
    "    img = tf.data.Dataset.from_tensor_slices(a).batch(1)\n",
    "    for i in img.take(BATCH_SIZE):\n",
    "        print(i)\n",
    "        yield [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54125f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"/yolo7/\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = [tf.uint8]\n",
    "converter.inference_output_type = [tf.uint8]\n",
    "converter.representative_dataset=rep_data_gen\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800daf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
