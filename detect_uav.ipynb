{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec344f1b-5c44-4bed-917a-2228779fb663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from shutil import copyfile, copytree, move\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dda96111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b37e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir('data/images/train')\n",
    "labels = os.listdir('data/labels/train')\n",
    "# s = []\n",
    "random.shuffle(images)\n",
    "# for image_name in tqdm(images):\n",
    "#     l1 = image_name\n",
    "#     l2 = '.'.join(l1.split('.')[:-1])\n",
    "#     if os.path.exists(os.path.join('data/labels/train', str(l2)+'.txt')):\n",
    "#         pass\n",
    "#     else:\n",
    "#         s.append(l1)\n",
    "# print(s)\n",
    "\n",
    "# l1 ='37_JPG.rf.a75cce59ed7182eee7aa119feb716230.jpg'\n",
    "# l2 = '.'.join(l1.split('.')[:-1])\n",
    "\n",
    "# move(os.path.join('data/images/train', l1), \n",
    "#          os.path.join('data/images/valid', l1))\n",
    "# if os.path.exists(os.path.join('data/labels/train', str(l2)+'.txt')):\n",
    "#         move(os.path.join('data/labels/train', str(l2)+'.txt'), \n",
    "#              os.path.join('data/labels/valid', str(l2)+'.txt'))\n",
    "\n",
    "\n",
    "\n",
    "# for label in labels:\n",
    "#     print(label)\n",
    "#     print(label.split('.')[:-1])\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb8f0d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02398371696472168,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 339,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98752675d30843fc89bfd33ab9a6d4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_name in tqdm(images[:int(0.2*len(images))]):\n",
    "    l1 = image_name\n",
    "    l2 = '.'.join(l1.split('.')[:-1])\n",
    "\n",
    "#     move(os.path.join('data/images/train', l1), \n",
    "#              os.path.join('data/images/valid', l1))\n",
    "    if os.path.exists(os.path.join('data/labels/train', str(l2)+'.txt')):\n",
    "            move(os.path.join('data/labels/train', str(l2)+'.txt'), \n",
    "                 os.path.join('data/labels/valid', str(l2)+'.txt'))\n",
    "            move(os.path.join('data/images/train', l1), \n",
    "             os.path.join('data/images/valid', l1))\n",
    "\n",
    "#     move(os.path.join(images, image_name), \n",
    "#          os.path.join('data/images/valid', image_name))\n",
    "#     l1 = image_name.split('.')[:-1]\n",
    "#     l1 = '.'.join(l1)\n",
    "#     if os.path.exists(os.path.join(labels, str(l1)+'.txt')):\n",
    "#         move(os.path.join(labels, str(l1)+'.txt'), \n",
    "#              os.path.join('data/labels/valid', str(l1)+'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c243270-073c-47b1-aee0-92241ba389d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'LADD'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "dirs = ['LDD/summer_moscow_2019', 'LDD/spring_korolev_2019', 'LDD/summer_tambov_2019', 'LDD/winter_moscow_2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ca88483-b9fb-4669-ae33-bec458a05945",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in dirs:\n",
    "    copytree(directory, save_dir, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0798b2bf-50bf-48f3-aaaa-a1decf9bd47f",
   "metadata": {},
   "source": [
    "### convert to yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb16a8f-d536-453d-96d5-fe873a545809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85efcf96-f5ab-46c9-b6d3-3dbf36e326d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "def xml2yolo(filepath, save_path):\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    annot = xmltodict.parse(' '.join(data))\n",
    "    img_h = int(annot['annotation']['size']['height'])\n",
    "    img_w = int(annot['annotation']['size']['width'])\n",
    "    peoples = []\n",
    "    if 'object' not in annot['annotation'].keys():\n",
    "        return\n",
    "    if isinstance(annot['annotation']['object'], dict):\n",
    "        annot['annotation']['object'] = [annot['annotation']['object']]\n",
    "    for obj in annot['annotation']['object']:\n",
    "        bbox = obj['bndbox']\n",
    "        y_min, x_min, y_max, x_max = int(bbox['ymin']),  int(bbox['xmin']),  int(bbox['ymax']),  int(bbox['xmax'])\n",
    "        w, h = x_max - x_min, y_max - y_min\n",
    "        x_c = x_min + w//2\n",
    "        y_c = y_min + h//2\n",
    "        w /= img_w\n",
    "        h /= img_h\n",
    "        x_c /= img_w\n",
    "        y_c /= img_h\n",
    "        peoples.append(f\"0 {x_c} {y_c} {w} {h}\")\n",
    "    \n",
    "    write_txt(peoples, save_path)\n",
    "\n",
    "def write_txt(data, save_path):\n",
    "    with open(save_path, 'w') as f:\n",
    "        for line in data:\n",
    "            f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40bb6220-d82f-405a-90af-16775ef5393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = 'LADD/labels'\n",
    "annot_dir = 'LADD/Annotations'\n",
    "os.makedirs(labels_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0ee13c-e9f6-4fc6-8ae5-0d0efa755e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0157318115234375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1422,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036f0d22c7564b90a6a2b34956b5d39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for file in tqdm(os.listdir(annot_dir)):\n",
    "    xml2yolo(os.path.join(annot_dir, file), os.path.join(labels_dir, file.split('.')[0]+'.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065993d6-8a2d-4b17-a257-1a49ee038bec",
   "metadata": {},
   "source": [
    "### TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ea9e2-0544-4065-8af8-bb2274efe717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "def parse_shape(shape):\n",
    "    data = []\n",
    "    start = []\n",
    "    end = []\n",
    "    \n",
    "    for index, s in enumerate(shape):\n",
    "        if s=='{':\n",
    "            start.append(index)\n",
    "        if s=='}':\n",
    "            end.append(index+1)\n",
    "    \n",
    "    for s, e in zip(start, end):\n",
    "        data.append(json.loads(shape[s:e]))\n",
    "    return data\n",
    "\n",
    "def shape2yolo(shape, img_path, save_path):\n",
    "    data = parse_shape(shape)\n",
    "    h, w, _ = cv2.imread(img_path).shape\n",
    "    peoples = []\n",
    "    \n",
    "    for i in data:\n",
    "        x_c, y_c, w_2 = i['cx'], i['cy'], i['r']\n",
    "        w_2 = w_2*2/w\n",
    "        x_c /= w\n",
    "        y_c /= h\n",
    "        peoples.append(f\"0 {x_c} {y_c} {w_2} {w_2}\")\n",
    "    \n",
    "    write_txt(peoples, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b0ec0-7500-403b-898e-bd40181edc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', delimiter=',')\n",
    "df[df['count_region']>0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7864d-1e8d-4c88-b819-61c033ffeee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_basedataset = 'train'\n",
    "omsk_dataset_full = 'omsk_full'\n",
    "LADD_images = 'LADD/JPEGImages'\n",
    "LADD_labels = 'LADD/labels'\n",
    "\n",
    "os.makedirs(os.path.join(omsk_dataset_full, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(omsk_dataset_full, 'labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(omsk_dataset_full, 'test/images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(omsk_dataset_full, 'test/labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(omsk_dataset_full, 'train/images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(omsk_dataset_full, 'train/labels'), exist_ok=True)\n",
    "\n",
    "for index, row in df[df['count_region']>0].iterrows():\n",
    "    copyfile(os.path.join(train_path_basedataset, row['ID_img']), \n",
    "             os.path.join(omsk_dataset_full, 'train/images', row['ID_img']))\n",
    "    shape = row['region_shape']\n",
    "    shape2yolo(shape, os.path.join(train_path_basedataset, row['ID_img']), \n",
    "               os.path.join(omsk_dataset_full, 'train/labels', row['ID_img'].split('.')[0]+'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f0921-5c9c-4c35-b04e-f9fc428daaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "copytree('LADD/labels', os.path.join(omsk_dataset_full, 'labels'), dirs_exist_ok=True)\n",
    "copytree('LADD/JPEGImages', os.path.join(omsk_dataset_full, 'images'), dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e601a9-303b-4309-91f8-24719458c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(LADD_images)\n",
    "random.shuffle(images)\n",
    "\n",
    "for image_name in images[:int(0.2*len(images))]:\n",
    "    move(os.path.join(LADD_images, image_name), \n",
    "         os.path.join(omsk_dataset_full, 'test/images', image_name))\n",
    "    if os.path.exists(os.path.join(LADD_labels, image_name.split('.')[0]+'.txt')):\n",
    "        move(os.path.join(LADD_labels, image_name.split('.')[0]+'.txt'), \n",
    "             os.path.join(omsk_dataset_full, 'test/labels', image_name.split('.')[0]+'.txt'))\n",
    "        \n",
    "move(LADD_images, os.path.join(omsk_dataset_full, 'train'))\n",
    "move(LADD_labels, os.path.join(omsk_dataset_full, 'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2ba2f-7e68-46e4-9236-b363ad93b792",
   "metadata": {},
   "source": [
    "# added empty images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d2988-ac4c-4f7d-b64e-32f9d8506037",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_images = df[df['count_region']==0]['ID_img'].to_list()\n",
    "random.shuffle(empty_images)\n",
    "\n",
    "for image in empty_images[:350]:\n",
    "    copyfile(os.path.join(train_path_basedataset, image), \n",
    "             os.path.join(omsk_dataset_full, 'train/images', image))\n",
    "    \n",
    "for image in empty_images[-350:]:\n",
    "    copyfile(os.path.join(train_path_basedataset, image), \n",
    "             os.path.join(omsk_dataset_full, 'test/images', image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da39be-ee35-4d2f-8fb4-4c57c53998c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90355d0c-632f-4244-96b5-2acb728a4a78",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05121166-55f6-4034-bfaa-3e5b6d673fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "cd \"yolov5\"\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d31c2-5680-40e2-be92-4e9fffd9f40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python train.py --img 1280 --batch -1 --epochs 100 --data \"/home/jovyan/omsk_hack.yaml\" --weights yolov5m6.pt --project \"hackaton_omsk_find_people\" --name \"yolov5m6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b183ff2-2ad7-4802-b996-c938577f3792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python detect.py --source \"/home/jovyan/test\" --weights \"/home/jovyan/yolov5/hackaton_omsk_find_people/yolov5m6/weights/best.pt\" --save-txt --save-conf --name \"yolov5m6_people_test\" --imgsz 1280 --exist-ok --conf-thres 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225e58f-143a-4745-b1b7-1d75e32c7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(label_path, img_path, th=0.3):\n",
    "    with open(os.path.join(label_path), 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    h, w, _ = cv2.imread(img_path).shape\n",
    "    lines = [line.rstrip().split(' ') for line in lines]\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        cl, xc, yc, w_, h_, t = list(map(float, line))\n",
    "        xc*=w\n",
    "        yc*=h\n",
    "        w_*=w\n",
    "        h_*=h\n",
    "        if t>=th:\n",
    "            result.append(f\"{{\\\"cx\\\":{xc},\\\"cy\\\":{yc},\\\"r\\\":{max(w_,h_)}}}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0cf07-4909-4f37-91ec-5703c33660f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = '/home/jovyan/yolov5/runs/detect/yolov5m6_people_test/labels'\n",
    "test_images_path = '/home/jovyan/hack/find_people/test'\n",
    "res = {}\n",
    "for file in tqdm(os.listdir(labels)):\n",
    "    if os.path.exists(os.path.join(test_images_path, file.split('.')[0]+'.JPG')):\n",
    "        predict =read_txt(os.path.join(labels, file), os.path.join(test_images_path, file.split('.')[0]+'.JPG'))\n",
    "    else: \n",
    "        predict=read_txt(os.path.join(labels, file), os.path.join(test_images_path, file.split('.')[0]+'.jpg'))\n",
    "    res[file.split('.')[0]] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf72d3d-94bb-4888-b292-33c919f2aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['ID_img','region_shape'])\n",
    "\n",
    "for file in tqdm(os.listdir(test_images_path)):\n",
    "    if file.split('.')[0] not in res:\n",
    "        res[file.split('.')[0]] = 0\n",
    "    df = df.append({'ID_img':file,'region_shape':res[file.split('.')[0]]}, ignore_index=True)\n",
    "    \n",
    "df.to_csv(r'/home/jovyan/omsk_solution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
