{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"FQx5H9TJ0nd-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670680299239,"user_tz":-180,"elapsed":2603,"user":{"displayName":"Denis Nugamanov","userId":"09874411685126779460"}},"outputId":"9f40bc88-1d45-454e-abb7-3e4634e2a5dd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# –ù–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª"],"metadata":{"id":"csZjfv3HNmV3"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm_notebook as tqdm\n","import torch\n","import os"],"metadata":{"id":"A9Yn6Je51AoT","executionInfo":{"status":"ok","timestamp":1670680303476,"user_tz":-180,"elapsed":2076,"user":{"displayName":"Denis Nugamanov","userId":"09874411685126779460"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists('yolov7'):\n","    !git clone https://github.com/WongKinYiu/yolov7.git\n"," \n","%cd yolov7\n"," \n","!pip install -r requirements.txt"],"metadata":{"id":"ExuGUcxH1w4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys"],"metadata":{"id":"DMwBTWN-6GRG","executionInfo":{"status":"ok","timestamp":1670680312567,"user_tz":-180,"elapsed":519,"user":{"displayName":"Denis Nugamanov","userId":"09874411685126779460"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["sys.path.append('/content/yolov7')"],"metadata":{"id":"iUkSx4CD1qR-","executionInfo":{"status":"ok","timestamp":1670678953691,"user_tz":-180,"elapsed":3,"user":{"displayName":"Denis Nugamanov","userId":"09874411685126779460"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import gc\n","\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXW48yX251f1","executionInfo":{"status":"ok","timestamp":1670680314547,"user_tz":-180,"elapsed":711,"user":{"displayName":"Denis Nugamanov","userId":"09874411685126779460"}},"outputId":"22cabca8-daf2-4977-fa41-2f2d79899a33"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"3JizrS4r6IXz","executionInfo":{"status":"ok","timestamp":1670680316052,"user_tz":-180,"elapsed":5,"user":{"displayName":"Denis Nugamanov","userId":"09874411685126779460"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"id":"gpzUs2ZOK_3u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd /content/yolov7 && python train_aux.py --workers 8 --batch-size 4 --data /content/drive/MyDrive/detect_people/detect.yaml --img 1280 1280 --epochs 300 --cfg cfg/training/yolov7-w6.yaml --weights '/content/drive/MyDrive/detect_people/yolov7-w6_training.pt' --name yolov7-w6-HD --hyp data/hyp.scratch.custom.yaml --single-cls\n"],"metadata":{"id":"uMO76wb75wMY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ba4a5fe-0ecd-4718-a6dc-30d7d3c34d91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["YOLOR üöÄ v0.1-116-g8c0bf3f torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","Namespace(adam=False, artifact_alias='latest', batch_size=4, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7-w6.yaml', data='/content/drive/MyDrive/detect_people/detect.yaml', device='', entity=None, epochs=300, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.custom.yaml', image_weights=False, img_size=[1280, 1280], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='yolov7-w6-HD', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov7-w6-HD8', save_period=-1, single_cls=True, sync_bn=False, total_batch_size=4, upload_dataset=False, v5_metric=False, weights='/content/drive/MyDrive/detect_people/yolov7-w6_training.pt', workers=8, world_size=1)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1         0  models.common.ReOrg                     []                            \n","  1                -1  1      7040  models.common.Conv                      [12, 64, 3, 1]                \n","  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  3                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  4                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 11                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n"," 12                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 13                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 16                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 17                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 18  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 19                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 20                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n"," 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 22                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 23                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 25                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 26                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 27  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 28                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 29                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n"," 30                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 31                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 32                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n"," 33                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n"," 34                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n"," 35                -1  1   1327872  models.common.Conv                      [384, 384, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1181184  models.common.Conv                      [1536, 768, 1, 1]             \n"," 38                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n"," 42                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n"," 43                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n"," 44                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n"," 45  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 46                -1  1   2099200  models.common.Conv                      [2048, 1024, 1, 1]            \n"," 47                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 48                -1  1    197376  models.common.Conv                      [512, 384, 1, 1]              \n"," 49                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 50                37  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 51          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 52                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 53                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 54                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n"," 55                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n"," 56                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n"," 57                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n"," 58[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 59                -1  1    590592  models.common.Conv                      [1536, 384, 1, 1]             \n"," 60                -1  1     98816  models.common.Conv                      [384, 256, 1, 1]              \n"," 61                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 62                28  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 63          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 64                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 65                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 66                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 67                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 68                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 69                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 70[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 71                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 72                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 73                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 74                19  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 75          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 76                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 77                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 78                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 79                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 80                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 81                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 82[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 83                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 84                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n"," 85          [-1, 71]  1         0  models.common.Concat                    [1]                           \n"," 86                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 87                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 88                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 89                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 90                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 91                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 92[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 93                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 94                -1  1    885504  models.common.Conv                      [256, 384, 3, 2]              \n"," 95          [-1, 59]  1         0  models.common.Concat                    [1]                           \n"," 96                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 97                -2  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 98                -1  1    663936  models.common.Conv                      [384, 192, 3, 1]              \n"," 99                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n","100                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n","101                -1  1    332160  models.common.Conv                      [192, 192, 3, 1]              \n","102[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","103                -1  1    590592  models.common.Conv                      [1536, 384, 1, 1]             \n","104                -1  1   1770496  models.common.Conv                      [384, 512, 3, 2]              \n","105          [-1, 47]  1         0  models.common.Concat                    [1]                           \n","106                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n","107                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n","108                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n","109                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","110                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","111                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","112[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","113                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","114                83  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n","115                93  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n","116               103  1   2655744  models.common.Conv                      [384, 768, 3, 1]              \n","117               113  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n","118                83  1    369280  models.common.Conv                      [128, 320, 3, 1]              \n","119                71  1   1475840  models.common.Conv                      [256, 640, 3, 1]              \n","120                59  1   3319680  models.common.Conv                      [384, 960, 3, 1]              \n","121                47  1   5900800  models.common.Conv                      [512, 1280, 3, 1]             \n","122[114, 115, 116, 117, 118, 119, 120, 121]  1    106456  models.yolo.IAuxDetect                  [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024, 320, 640, 960, 1280]]\n","/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 477 layers, 80944472 parameters, 80944472 gradients, 102.4 GFLOPS\n","\n","Transferred 646/668 items from /content/drive/MyDrive/detect_people/yolov7-w6_training.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 115 .bias, 115 conv.weight, 115 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/detect_people/data/labels/train.cache' images and labels... 1308 found, 42 missing, 3 empty, 0 corrupted: 100% 1350/1350 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/detect_people/data/labels/valid.cache' images and labels... 331 found, 15 missing, 0 empty, 0 corrupted: 100% 346/346 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.30, Best Possible Recall (BPR) = 0.9763. Attempting to improve anchors, please wait...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 15 of 4806 labels are < 3 pixels in size.\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 4806 points...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9998 best possible recall, 11.34 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=1280, metric_all=0.534/0.848-mean/best, past_thr=0.553-mean: 6,9,  14,12,  12,17,  23,14,  17,19,  14,25,  24,23,  33,16,  18,32,  20,43,  45,20,  32,30\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8560: 100% 1000/1000 [00:07<00:00, 141.54it/s]\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9998 best possible recall, 11.20 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=1280, metric_all=0.547/0.856-mean/best, past_thr=0.572-mean: 4,9,  12,12,  13,17,  18,13,  17,19,  13,26,  26,15,  18,27,  22,21,  38,16,  19,39,  30,28\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n","\n","Image sizes 1280 train, 1280 test\n","Using 2 dataloader workers\n","Logging results to runs/train/yolov7-w6-HD8\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     0/299     9.88G    0.1069   0.03026         0    0.1372        13      1280: 100% 338/338 [23:32<00:00,  4.18s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 44/44 [01:33<00:00,  2.13s/it]\n","                 all         346        1038       0.297       0.304       0.171      0.0492\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     1/299     9.86G   0.07396   0.01436         0   0.08832        12      1280: 100% 338/338 [22:35<00:00,  4.01s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 44/44 [01:47<00:00,  2.45s/it]\n","                 all         346        1038     0.00101      0.0597    7.98e-05    1.68e-05\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","     2/299     9.86G   0.07036   0.01421         0   0.08458         7      1280:  98% 330/338 [22:53<00:43,  5.42s/it]"]}]},{"cell_type":"code","source":["# --cache-images  --device 0"],"metadata":{"id":"i6Ug9I2zBtL4","executionInfo":{"status":"ok","timestamp":1670680292808,"user_tz":-180,"elapsed":662,"user":{"displayName":"Denis Nugamanov","userId":"09874411685126779460"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# !cd yolov5 && python train.py --img 4096 --batch 1 --epochs 500 --patience 20 --data /content/drive/MyDrive/omsk/omsk_col.yaml --weights yolov5m.pt --cache"],"metadata":{"id":"Hp9PPWUT6R1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r \"/content/yolov5/runs/train/exp2/weights/best.pt\" \"/content/drive/MyDrive/detect_people\""],"metadata":{"id":"7yuicdovCJXV"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1s7aTKdDiomn_YhzV6GzbkdJAH-9zCV_7","timestamp":1670672378293}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}